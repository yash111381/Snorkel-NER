{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\I517193\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\I517193\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from snorkel.labeling import labeling_function\n",
    "import re\n",
    "import editdistance as ed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.en import English\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import wordnet \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from snorkel.labeling import PandasLFApplier, LFApplier, LFAnalysis\n",
    "from snorkel.analysis import get_label_buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema\n",
    "* The data consist of the queries users searched for, by voice, converted to text\n",
    "* All queries are labeled with their tags (each unigram is labeled with the entity name)\n",
    "* The entities covered are as follows:\n",
    "  * Restuarant_name\n",
    "  * Rating\n",
    "  * Amenity\n",
    "  * Location\n",
    "  * Price\n",
    "  * Hours\n",
    "  * Dish\n",
    "  * Cuisine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing the file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Separating each candidate noun phrase from the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_df_file(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        size = len(lines) \n",
    "        idx_list = [idx + 1 for idx, val in\n",
    "                enumerate(lines) if val == '\\n'] \n",
    "        res = [lines[i: j-1] for i, j in\n",
    "            zip([0] + idx_list, idx_list + \n",
    "            ([size] if idx_list[-1] != size else []))] \n",
    "        queries = ['' for i in range(len(res))]\n",
    "        tags = []\n",
    "        unigrams = []\n",
    "        words = []\n",
    "        poss = []\n",
    "        for i, ele in enumerate(res):\n",
    "            flag = False\n",
    "            tempWords = []\n",
    "            temT = []\n",
    "            temW = []\n",
    "            temPos = []\n",
    "            for j, actual_str in enumerate(ele):\n",
    "                res[i][j] = actual_str.split('\\t')\n",
    "                res[i][j][-1] = res[i][j][-1].replace('\\n', '')\n",
    "                if res[i][j][0][:2]==\"B-\" or res[i][j][0][:2]==\"I-\":\n",
    "                    if flag:\n",
    "                        if tempTag == res[i][j][0][2:]:\n",
    "                            tempWords.append(res[i][j][-1])\n",
    "                        else:\n",
    "                            temT.append(tempTag)\n",
    "                            temW.append(' '.join(tempWords))\n",
    "                            pos[-1] = j-1\n",
    "                            temPos.append(pos)\n",
    "                            tempWords = []\n",
    "                            pos = [j,j]\n",
    "                            tempWords.append(res[i][j][-1])\n",
    "                            tempTag = res[i][j][0][2:]\n",
    "                        # tempTag.append\n",
    "                    else:\n",
    "                        tempWords = []\n",
    "                        tempWords.append(res[i][j][-1])\n",
    "                        pos = [j,j]\n",
    "                        tempTag = res[i][j][0][2:]\n",
    "                        flag = True\n",
    "    #             elif res[i][j][0][:2]==\"I-\":\n",
    "    #                 tempWords.append(res[i][j][-1])\n",
    "    #                 temT.append(res[i][j][0][2:])\n",
    "    #                 temW.append(' '.join(tempWords))\n",
    "    #                 flag = False\n",
    "                else:\n",
    "                    if flag:\n",
    "                        temT.append(tempTag)\n",
    "                        temW.append(' '.join(tempWords))\n",
    "                        pos[-1] = j-1\n",
    "                        temPos.append(pos)\n",
    "                        flag = False\n",
    "                if j!=0:\n",
    "                    queries[i] = queries[i] + ' ' + res[i][j][-1]\n",
    "                else:\n",
    "                    queries[i] = res[i][j][-1]\n",
    "            if flag:\n",
    "                temT.append(tempTag)\n",
    "                temW.append(' '.join(tempWords))\n",
    "                pos[-1] = j\n",
    "                temPos.append(pos)\n",
    "                flag = False\n",
    "            tags.append(temT)\n",
    "            words.append(temW)\n",
    "            poss.append(temPos)\n",
    "    df_queries = []\n",
    "    df_pos_start = []\n",
    "    df_pos_end = []\n",
    "    n_grams = []\n",
    "    df_tags = []\n",
    "    for i, ele in enumerate(res):\n",
    "        for j in range(len(tags[i])):\n",
    "            df_queries.append(queries[i])\n",
    "            df_tags.append(tags[i][j])\n",
    "            df_pos_start.append(poss[i][j][0])\n",
    "            df_pos_end.append(poss[i][j][1])\n",
    "            n_grams.append(words[i][j])\n",
    "    return pd.DataFrame({\"n_grams\": n_grams, \"Tag\": df_tags, \"Query\": df_queries, \"Pos_start\": df_pos_start, \"Pos_end\":df_pos_end})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the train and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ret_df_file(\"../Datasets/MITRestuarant/restauranttrain.bio\")\n",
    "df_test = ret_df_file(\"../Datasets/MITRestuarant/restauranttest.bio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15363, 5)\n",
      "(3151, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_grams</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Query</th>\n",
       "      <th>Pos_start</th>\n",
       "      <th>Pos_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 start</td>\n",
       "      <td>Rating</td>\n",
       "      <td>2 start restaurants with inside dining</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inside dining</td>\n",
       "      <td>Amenity</td>\n",
       "      <td>2 start restaurants with inside dining</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 star</td>\n",
       "      <td>Rating</td>\n",
       "      <td>5 star resturants in my town</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in my town</td>\n",
       "      <td>Location</td>\n",
       "      <td>5 star resturants in my town</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hong kong</td>\n",
       "      <td>Restaurant_Name</td>\n",
       "      <td>98 hong kong restaurant reasonable prices</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_grams              Tag                                      Query  \\\n",
       "0        2 start           Rating     2 start restaurants with inside dining   \n",
       "1  inside dining          Amenity     2 start restaurants with inside dining   \n",
       "2         5 star           Rating               5 star resturants in my town   \n",
       "3     in my town         Location               5 star resturants in my town   \n",
       "4      hong kong  Restaurant_Name  98 hong kong restaurant reasonable prices   \n",
       "\n",
       "   Pos_start  Pos_end  \n",
       "0          0        1  \n",
       "1          4        5  \n",
       "2          0        1  \n",
       "3          3        5  \n",
       "4          1        2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_grams</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Query</th>\n",
       "      <th>Pos_start</th>\n",
       "      <th>Pos_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>four star</td>\n",
       "      <td>Rating</td>\n",
       "      <td>a four star restaurant with a bar</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>with a</td>\n",
       "      <td>Location</td>\n",
       "      <td>a four star restaurant with a bar</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bar</td>\n",
       "      <td>Amenity</td>\n",
       "      <td>a four star restaurant with a bar</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asian</td>\n",
       "      <td>Cuisine</td>\n",
       "      <td>any asian cuisine around</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>around</td>\n",
       "      <td>Location</td>\n",
       "      <td>any asian cuisine around</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_grams       Tag                              Query  Pos_start  Pos_end\n",
       "0  four star    Rating  a four star restaurant with a bar          1        2\n",
       "1     with a  Location  a four star restaurant with a bar          4        5\n",
       "2        bar   Amenity  a four star restaurant with a bar          6        6\n",
       "3      asian   Cuisine           any asian cuisine around          1        1\n",
       "4     around  Location           any asian cuisine around          3        3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_noun_chunks_limited(df_train):\n",
    "    list_of_queries = df_train.Query.unique()\n",
    "    queries_train = []\n",
    "    tags_train = []\n",
    "    phrases_train = []\n",
    "    pos_S = []\n",
    "    pos_E = []\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    for query in list_of_queries:\n",
    "        doc = nlp(query)\n",
    "        positions_start = list(df_train.Pos_start[df_train.Query==query])\n",
    "        positions_end = list(df_train.Pos_end[df_train.Query==query])\n",
    "        for noun in doc.noun_chunks:\n",
    "            flag = False\n",
    "            for i in range(len(positions_start)):\n",
    "                # checking intersection>0 and extra words in noun_chunk not more than 2 and difference \n",
    "                # between the phrases of not more than 2 words\n",
    "                if len(set(list(range(noun.start, noun.end))) & \\\n",
    "                       set(list(range(positions_start[i], positions_end[i]+1))))>0 \\\n",
    "                and (len(set(list(range(noun.start, noun.end))).difference(set(list(range(positions_start[i], \\\n",
    "                                                                                            positions_end[i]+1)))))<=2 \\\n",
    "                    and len(set(list(range(positions_start[i], positions_end[i]+1))).difference(set(list(range(noun.start, noun.end)))))<=2):\n",
    "                    queries_train.append(query)\n",
    "                    tags_train.append(list(df_train.Tag[np.logical_and(df_train.Query==query, \\\n",
    "                                                                  df_train.Pos_start==positions_start[i])])[0])\n",
    "                    phrases_train.append(noun.text)\n",
    "                    pos_S.append(noun.start)\n",
    "                    pos_E.append(noun.end-1)\n",
    "                    flag = True\n",
    "                    break\n",
    "    return pd.DataFrame({\"n_grams\": phrases_train, \"Tag\": tags_train, \\\n",
    "                                \"Query\": queries_train, \"Pos_start\": pos_S, \"Pos_end\":pos_E})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_limited_chunks = obtain_noun_chunks_limited(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_limited_chunks = obtain_noun_chunks_limited(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_grams</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Query</th>\n",
       "      <th>Pos_start</th>\n",
       "      <th>Pos_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a four star restaurant</td>\n",
       "      <td>Rating</td>\n",
       "      <td>a four star restaurant with a bar</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a bar</td>\n",
       "      <td>Location</td>\n",
       "      <td>a four star restaurant with a bar</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>any asian cuisine</td>\n",
       "      <td>Cuisine</td>\n",
       "      <td>any asian cuisine around</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>any bbq places</td>\n",
       "      <td>Cuisine</td>\n",
       "      <td>any bbq places open before 5 nearby</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>any dancing establishments</td>\n",
       "      <td>Location</td>\n",
       "      <td>any dancing establishments with reasonable pri...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      n_grams       Tag  \\\n",
       "0      a four star restaurant    Rating   \n",
       "1                       a bar  Location   \n",
       "2           any asian cuisine   Cuisine   \n",
       "3              any bbq places   Cuisine   \n",
       "4  any dancing establishments  Location   \n",
       "\n",
       "                                               Query  Pos_start  Pos_end  \n",
       "0                  a four star restaurant with a bar          0        3  \n",
       "1                  a four star restaurant with a bar          5        6  \n",
       "2                           any asian cuisine around          0        2  \n",
       "3                any bbq places open before 5 nearby          0        2  \n",
       "4  any dancing establishments with reasonable pri...          0        2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_limited_chunks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rating', 'Amenity', 'Location', 'Hours', 'Dish', 'Cuisine',\n",
       "       'Price', 'Restaurant_Name'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_limited_chunks.Tag.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATING = 0\n",
    "AMENITY = 1\n",
    "LOCATION = 2\n",
    "RESTUARANT_NAME = 3\n",
    "HOURS = 4\n",
    "DISH = 5\n",
    "CUISINE = 6\n",
    "PRICE = 7\n",
    "NO_TAG = 8\n",
    "ABSTAIN  = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Rating'] = RATING\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Amenity'] = AMENITY\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Location'] = LOCATION\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Restaurant_Name'] = RESTUARANT_NAME\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Hours'] = HOURS\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Dish'] = DISH\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Cuisine'] = CUISINE\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Price'] = PRICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Labelling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labelling functions for Rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_rating_star(x):\n",
    "    # Returns a label of rating if pattern of digit star's found in the phrase\n",
    "    query = x.Query.lower()\n",
    "    if re.findall(\"[\\d]+[\\W]?star\", query):\n",
    "        return RATING\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_rating_adj(x):\n",
    "    # Returns a label of rating if any adjective within the edit distance or the base form of adjective is found in the phrase\n",
    "    adjectives = ['fresh', 'recommended', 'fair', 'recommendation', 'rated'\n",
    "       'terrific', 'well', 'awesome', 'awards', 'authentic', 'pleasing', 'favorite',\n",
    "        'lovely', 'really', 'decent', 'busy', 'superior','average'\n",
    "       'famous', 'poor', 'decent', 'simple', 'real', 'popular', 'wonderful',\n",
    "       'casual', 'perfect', 'massive', 'nearby', 'nice',\n",
    "       'delicious', 'winning', 'favourite',  'negative', 'award', 'positive', 'fancy',\n",
    "       'outstanding', 'good', 'amazing', 'recommend',\n",
    "       'strong', 'value','incredible',\n",
    "       'fantastic', 'classy', 'top', 'former', 'rated','reviews','horrible','terrible', \n",
    "       'local', 'excellent', 'place',\n",
    "       'tasty', 'rate', 'high', 'great']\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    for word in x.Query.lower().split():\n",
    "        for adjective in adjectives:\n",
    "            if ed.eval(adjective, word)<=1 or lemmatiser.lemmatize(word, pos = \"a\")==adjective:\n",
    "                return RATING\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_rating_adj_syn(x):\n",
    "    # Returns a label of rating if any word in the phrase is a synonym or an antonym of the mentioned words\n",
    "    adjectives = ['fresh', 'recommended', 'fair', 'recommendation', 'rated'\n",
    "       'terrific', 'well', 'awesome', 'awards', 'authentic', 'pleasing', 'favorite',\n",
    "        'lovely', 'really', 'decent', 'busy', 'superior',\n",
    "       'famous', 'poor', 'decent', 'simple', 'real', 'popular', 'wonderful',\n",
    "       'casual', 'perfect', 'massive', 'nearby', 'nice',\n",
    "       'delicious', 'winning', 'favourite',  'negative', 'award', 'positive', 'fancy',\n",
    "       'outstanding', 'good', 'amazing', 'recommend',\n",
    "       'strong', 'value','incredible',\n",
    "       'fantastic', 'classy', 'top', 'former', 'rated','reviews','horrible','terrible', \n",
    "       'local', 'excellent', 'place',\n",
    "       'tasty', 'rate', 'high', 'great']\n",
    "    synonyms = [] \n",
    "    antonyms = [] \n",
    "    for adj in adjectives:\n",
    "        for syn in wordnet.synsets(adj): \n",
    "            for l in syn.lemmas(): \n",
    "                synonyms.append(l.name()) \n",
    "                if l.antonyms(): \n",
    "                    antonyms.append(l.antonyms()[0].name()) \n",
    "    \n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    for word in x.Query.lower().split():\n",
    "        for adjective in synonyms:\n",
    "            if ed.eval(adjective, word)<=1 or lemmatiser.lemmatize(word, pos = \"a\")==adjective:\n",
    "                return RATING\n",
    "        for adjective in antonyms:\n",
    "            if ed.eval(adjective, word)<=1 or lemmatiser.lemmatize(word, pos = \"a\")==adjective:\n",
    "                return RATING\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labelling functions for Amenity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_amenity_lem(x):\n",
    "    # Returns a label of rating if pattern of digit star's found in the phrase\n",
    "    amenities = ['formal', 'outdoor', 'friendly', 'parking', 'special'\n",
    "       'quiet', 'smoking', 'atmosphere', 'anniversary', 'birthday', 'tourist', 'reservation']\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    for word in x.Query.lower().split():\n",
    "        for adjective in amenities:\n",
    "            if ed.eval(adjective, word)<=1 or lemmatiser.lemmatize(word, pos = \"a\")==adjective:\n",
    "                return AMENITY\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_amenity_syn(x):\n",
    "    # Returns a label of rating if pattern of digit star's found in the phrase\n",
    "    amenities = ['formal', 'outdoor', 'friendly', 'parking', 'special'\n",
    "       'quiet', 'smoking', 'atmosphere', 'anniversary', 'birthday', 'tourist', 'reservation']\n",
    "\n",
    "    synonyms = [] \n",
    "    antonyms = [] \n",
    "    for adj in amenities:\n",
    "        for syn in wordnet.synsets(adj): \n",
    "            for l in syn.lemmas(): \n",
    "                synonyms.append(l.name()) \n",
    "                if l.antonyms(): \n",
    "                    antonyms.append(l.antonyms()[0].name()) \n",
    "    \n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    for word in x.Query.lower().split():\n",
    "        for adjective in synonyms:\n",
    "            if ed.eval(adjective, word)<=1 or lemmatiser.lemmatize(word, pos = \"a\")==adjective:\n",
    "                return AMENITY\n",
    "        for adjective in antonyms:\n",
    "            if ed.eval(adjective, word)<=1 or lemmatiser.lemmatize(word, pos = \"a\")==adjective:\n",
    "                return AMENITY\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labeling function for Location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_location_prep(x):\n",
    "    # Returns a label of location if the word before the phrase is a preposition mentioned\n",
    "    if (x.Pos_start>=1 and x.Query.split()[x.Pos_start - 1].lower() in ['in', 'near', 'above', 'over', 'by', 'along', 'around']) or \\\n",
    "    (x.Pos_start>1 and x.Query.split()[x.Pos_start - 2].lower() in  ['in', 'near', 'above', 'over', 'by', 'along', 'on']):\n",
    "        return LOCATION\n",
    "    elif x.Pos_end + 1 <= (len(x.Query.strip().split()) - 1) \\\n",
    "    and x.Query.split()[x.Pos_end + 1].lower() in ['where']:\n",
    "        return LOCATION\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_amenity_train = df_train_limited_chunks[df_train_limited_chunks['Tag'].isin([0,1,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_lf_rating_amenity, df_test_lf_rating_amenity, y_lf_train, y_lf_test = train_test_split(df_rating_amenity_train.drop('Tag', axis = 1),\\\n",
    "                                                                                df_rating_amenity_train['Tag'], test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [lf_rating_star, lf_rating_adj, lf_rating_adj_syn, lf_amenity_lem, lf_amenity_syn, lf_location_prep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3243/3243 [01:28<00:00, 36.48it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1390/1390 [00:39<00:00, 35.54it/s]\n"
     ]
    }
   ],
   "source": [
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train_lf_rating_amenity)\n",
    "L_dev = applier.apply(df=df_test_lf_rating_amenity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelling function stars coverage: 1.6%\n",
      "Labelling function adjectives coverage: 51.6%\n",
      "Labelling function synonyms of adjectives coverage: 92.1%\n",
      "Labelling function lemmas of amenity coverage: 15.4%\n",
      "Labelling function synonyms of amenity coverage: 28.0%\n",
      "Labelling function synonyms of location coverage: 23.7%\n"
     ]
    }
   ],
   "source": [
    "coverage_stars, coverage_adjectives, coverage_synonyms, coverage_amenity_lem, coverage_amenity_syn, coverage_loc = \\\n",
    "(L_train != ABSTAIN).mean(axis=0)\n",
    "print(f\"Labelling function stars coverage: {coverage_stars * 100:.1f}%\")\n",
    "print(f\"Labelling function adjectives coverage: {coverage_adjectives * 100:.1f}%\")\n",
    "print(f\"Labelling function synonyms of adjectives coverage: {coverage_synonyms * 100:.1f}%\")\n",
    "print(f\"Labelling function lemmas of amenity coverage: {coverage_amenity_lem * 100:.1f}%\")\n",
    "print(f\"Labelling function synonyms of amenity coverage: {coverage_amenity_syn * 100:.1f}%\")\n",
    "print(f\"Labelling function synonyms of location coverage: {coverage_loc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_rating_star</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>0.016343</td>\n",
       "      <td>0.008017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_rating_adj</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.515880</td>\n",
       "      <td>0.515572</td>\n",
       "      <td>0.213383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_rating_adj_syn</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.921061</td>\n",
       "      <td>0.753006</td>\n",
       "      <td>0.445883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_amenity_lem</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.154178</td>\n",
       "      <td>0.154178</td>\n",
       "      <td>0.134135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_amenity_syn</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.279988</td>\n",
       "      <td>0.277212</td>\n",
       "      <td>0.257169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_location_prep</th>\n",
       "      <td>5</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.237126</td>\n",
       "      <td>0.233734</td>\n",
       "      <td>0.233734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts\n",
       "lf_rating_star     0      [0]  0.016343  0.016343   0.008017\n",
       "lf_rating_adj      1      [0]  0.515880  0.515572   0.213383\n",
       "lf_rating_adj_syn  2      [0]  0.921061  0.753006   0.445883\n",
       "lf_amenity_lem     3      [1]  0.154178  0.154178   0.134135\n",
       "lf_amenity_syn     4      [1]  0.279988  0.277212   0.257169\n",
       "lf_location_prep   5      [2]  0.237126  0.233734   0.233734"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of unknown and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-dbefbca0a78e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLFAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mL_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlfs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlf_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_lf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\capstone\\lib\\site-packages\\snorkel\\labeling\\analysis.py\u001b[0m in \u001b[0;36mlf_summary\u001b[1;34m(self, Y, est_weights)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mconfusions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m             \u001b[0mcorrects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfusions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             incorrects = [\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\capstone\\lib\\site-packages\\snorkel\\labeling\\analysis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mconfusions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m             \u001b[0mcorrects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfusions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             incorrects = [\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of unknown and binary targets"
     ]
    }
   ],
   "source": [
    "LFAnalysis(L=L_dev, lfs=lfs).lf_summary(y_lf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
