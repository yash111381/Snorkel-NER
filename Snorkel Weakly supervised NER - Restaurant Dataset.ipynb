{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snorkel - Weakly Supervised NER on Restaurant Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing necessary modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\I517193\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\I517193\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import editdistance as ed\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from spacy.lang.en import English\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import wordnet \n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, LancasterStemmer\n",
    "from snorkel.labeling import PandasLFApplier, LFApplier, LFAnalysis, labeling_function\n",
    "from snorkel.analysis import get_label_buckets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from snorkel.labeling import LabelModel\n",
    "from snorkel.labeling import MajorityLabelVoter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema\n",
    "* The data consist of the queries users searched for, by voice, converted to text\n",
    "* All queries are labeled with their tags (each unigram is labeled with the entity name)\n",
    "* The entities covered are as follows:\n",
    "  * Restuarant_name\n",
    "  * Rating\n",
    "  * Amenity\n",
    "  * Location\n",
    "  * Price\n",
    "  * Hours\n",
    "  * Dish\n",
    "  * Cuisine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing the file**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Separating each candidate noun phrase from the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_df_file(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        size = len(lines) \n",
    "        idx_list = [idx + 1 for idx, val in\n",
    "                enumerate(lines) if val == '\\n'] \n",
    "        res = [lines[i: j-1] for i, j in\n",
    "            zip([0] + idx_list, idx_list + \n",
    "            ([size] if idx_list[-1] != size else []))] \n",
    "        queries = ['' for i in range(len(res))]\n",
    "        tags = []\n",
    "        unigrams = []\n",
    "        words = []\n",
    "        poss = []\n",
    "        for i, ele in enumerate(res):\n",
    "            flag = False\n",
    "            tempWords = []\n",
    "            temT = []\n",
    "            temW = []\n",
    "            temPos = []\n",
    "            for j, actual_str in enumerate(ele):\n",
    "                res[i][j] = actual_str.split('\\t')\n",
    "                res[i][j][-1] = res[i][j][-1].replace('\\n', '')\n",
    "                if res[i][j][0][:2]==\"B-\" or res[i][j][0][:2]==\"I-\":\n",
    "                    if flag:\n",
    "                        if tempTag == res[i][j][0][2:]:\n",
    "                            tempWords.append(res[i][j][-1])\n",
    "                        else:\n",
    "                            temT.append(tempTag)\n",
    "                            temW.append(' '.join(tempWords))\n",
    "                            pos[-1] = j-1\n",
    "                            temPos.append(pos)\n",
    "                            tempWords = []\n",
    "                            pos = [j,j]\n",
    "                            tempWords.append(res[i][j][-1])\n",
    "                            tempTag = res[i][j][0][2:]\n",
    "                        # tempTag.append\n",
    "                    else:\n",
    "                        tempWords = []\n",
    "                        tempWords.append(res[i][j][-1])\n",
    "                        pos = [j,j]\n",
    "                        tempTag = res[i][j][0][2:]\n",
    "                        flag = True\n",
    "                else:\n",
    "                    if flag:\n",
    "                        temT.append(tempTag)\n",
    "                        temW.append(' '.join(tempWords))\n",
    "                        pos[-1] = j-1\n",
    "                        temPos.append(pos)\n",
    "                        flag = False\n",
    "                if j!=0:\n",
    "                    queries[i] = queries[i] + ' ' + res[i][j][-1]\n",
    "                else:\n",
    "                    queries[i] = res[i][j][-1]\n",
    "            if flag:\n",
    "                temT.append(tempTag)\n",
    "                temW.append(' '.join(tempWords))\n",
    "                pos[-1] = j\n",
    "                temPos.append(pos)\n",
    "                flag = False\n",
    "            tags.append(temT)\n",
    "            words.append(temW)\n",
    "            poss.append(temPos)\n",
    "    df_queries = []\n",
    "    df_pos_start = []\n",
    "    df_pos_end = []\n",
    "    n_grams = []\n",
    "    df_tags = []\n",
    "    for i, ele in enumerate(res):\n",
    "        for j in range(len(tags[i])):\n",
    "            df_queries.append(queries[i])\n",
    "            df_tags.append(tags[i][j])\n",
    "            df_pos_start.append(poss[i][j][0])\n",
    "            df_pos_end.append(poss[i][j][1])\n",
    "            n_grams.append(words[i][j])\n",
    "    return pd.DataFrame({\"n_grams\": n_grams, \"Tag\": df_tags, \"Query\": df_queries, \"Pos_start\": df_pos_start, \"Pos_end\":df_pos_end})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the train and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = ret_df_file(\"../Datasets/MITRestuarant/restauranttrain.bio\")\n",
    "df_test = ret_df_file(\"../Datasets/MITRestuarant/restauranttest.bio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15363, 5)\n",
      "(3151, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_grams</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Query</th>\n",
       "      <th>Pos_start</th>\n",
       "      <th>Pos_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 start</td>\n",
       "      <td>Rating</td>\n",
       "      <td>2 start restaurants with inside dining</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inside dining</td>\n",
       "      <td>Amenity</td>\n",
       "      <td>2 start restaurants with inside dining</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5 star</td>\n",
       "      <td>Rating</td>\n",
       "      <td>5 star resturants in my town</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in my town</td>\n",
       "      <td>Location</td>\n",
       "      <td>5 star resturants in my town</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hong kong</td>\n",
       "      <td>Restaurant_Name</td>\n",
       "      <td>98 hong kong restaurant reasonable prices</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_grams              Tag                                      Query  \\\n",
       "0        2 start           Rating     2 start restaurants with inside dining   \n",
       "1  inside dining          Amenity     2 start restaurants with inside dining   \n",
       "2         5 star           Rating               5 star resturants in my town   \n",
       "3     in my town         Location               5 star resturants in my town   \n",
       "4      hong kong  Restaurant_Name  98 hong kong restaurant reasonable prices   \n",
       "\n",
       "   Pos_start  Pos_end  \n",
       "0          0        1  \n",
       "1          4        5  \n",
       "2          0        1  \n",
       "3          3        5  \n",
       "4          1        2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_grams</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Query</th>\n",
       "      <th>Pos_start</th>\n",
       "      <th>Pos_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>four star</td>\n",
       "      <td>Rating</td>\n",
       "      <td>a four star restaurant with a bar</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>with a</td>\n",
       "      <td>Location</td>\n",
       "      <td>a four star restaurant with a bar</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bar</td>\n",
       "      <td>Amenity</td>\n",
       "      <td>a four star restaurant with a bar</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asian</td>\n",
       "      <td>Cuisine</td>\n",
       "      <td>any asian cuisine around</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>around</td>\n",
       "      <td>Location</td>\n",
       "      <td>any asian cuisine around</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     n_grams       Tag                              Query  Pos_start  Pos_end\n",
       "0  four star    Rating  a four star restaurant with a bar          1        2\n",
       "1     with a  Location  a four star restaurant with a bar          4        5\n",
       "2        bar   Amenity  a four star restaurant with a bar          6        6\n",
       "3      asian   Cuisine           any asian cuisine around          1        1\n",
       "4     around  Location           any asian cuisine around          3        3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now I extract candidate noun phrases from the queries using nlp module's noun chunks**\n",
    "\n",
    "Also, to label the noun phrases, I am using the following assumptions:\n",
    "* The labeled noun phrase and the noun phrase extracted using nlp should have an intersection of more than one word\n",
    "* The absolute value of the difference in the number of words in the labelled and the extracted noun phrase should not be more than 2 words\n",
    "\n",
    "If both the above criteria are satisfied, then I label the noun phrase given by the nlp module using the label from the noun phrase already labelled.\n",
    "\n",
    "*Note: I need to do this as using the same noun phrase manually labelled would not be available at test time, and we should train the model in a similar way*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_noun_chunks_limited(df_train):\n",
    "    list_of_queries = df_train.Query.unique()\n",
    "    queries_train = []\n",
    "    tags_train = []\n",
    "    phrases_train = []\n",
    "    pos_S = []\n",
    "    pos_E = []\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    for query in list_of_queries:\n",
    "        doc = nlp(query)\n",
    "        positions_start = list(df_train.Pos_start[df_train.Query==query])\n",
    "        positions_end = list(df_train.Pos_end[df_train.Query==query])\n",
    "        for noun in doc.noun_chunks:\n",
    "            flag = False\n",
    "            for i in range(len(positions_start)):\n",
    "                # checking intersection>0 and extra words in noun_chunk not more than 2 and difference \n",
    "                # between the phrases of not more than 2 words\n",
    "                if len(set(list(range(noun.start, noun.end))) & \\\n",
    "                       set(list(range(positions_start[i], positions_end[i]+1))))>0 \\\n",
    "                and (len(set(list(range(noun.start, noun.end))).difference(set(list(range(positions_start[i], \\\n",
    "                                                                                            positions_end[i]+1)))))<=2 \\\n",
    "                    and len(set(list(range(positions_start[i], positions_end[i]+1))).difference(set(list(range(noun.start, noun.end)))))<=2):\n",
    "                    queries_train.append(query)\n",
    "                    tags_train.append(list(df_train.Tag[np.logical_and(df_train.Query==query, \\\n",
    "                                                                  df_train.Pos_start==positions_start[i])])[0])\n",
    "                    phrases_train.append(noun.text)\n",
    "                    pos_S.append(noun.start)\n",
    "                    pos_E.append(noun.end-1)\n",
    "                    flag = True\n",
    "                    break\n",
    "    return pd.DataFrame({\"n_grams\": phrases_train, \"Tag\": tags_train, \\\n",
    "                                \"Query\": queries_train, \"Pos_start\": pos_S, \"Pos_end\":pos_E})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_limited_chunks = obtain_noun_chunks_limited(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_limited_chunks = obtain_noun_chunks_limited(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_grams</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Query</th>\n",
       "      <th>Pos_start</th>\n",
       "      <th>Pos_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a four star restaurant</td>\n",
       "      <td>Rating</td>\n",
       "      <td>a four star restaurant with a bar</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a bar</td>\n",
       "      <td>Location</td>\n",
       "      <td>a four star restaurant with a bar</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>any asian cuisine</td>\n",
       "      <td>Cuisine</td>\n",
       "      <td>any asian cuisine around</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>any bbq places</td>\n",
       "      <td>Cuisine</td>\n",
       "      <td>any bbq places open before 5 nearby</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>any dancing establishments</td>\n",
       "      <td>Location</td>\n",
       "      <td>any dancing establishments with reasonable pri...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      n_grams       Tag  \\\n",
       "0      a four star restaurant    Rating   \n",
       "1                       a bar  Location   \n",
       "2           any asian cuisine   Cuisine   \n",
       "3              any bbq places   Cuisine   \n",
       "4  any dancing establishments  Location   \n",
       "\n",
       "                                               Query  Pos_start  Pos_end  \n",
       "0                  a four star restaurant with a bar          0        3  \n",
       "1                  a four star restaurant with a bar          5        6  \n",
       "2                           any asian cuisine around          0        2  \n",
       "3                any bbq places open before 5 nearby          0        2  \n",
       "4  any dancing establishments with reasonable pri...          0        2  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_limited_chunks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are the following types of entities available in the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rating', 'Amenity', 'Location', 'Hours', 'Dish', 'Cuisine',\n",
       "       'Price', 'Restaurant_Name'], dtype=object)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_limited_chunks.Tag.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the Labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we assign numeric labels to the entities and then change them in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RATING = 0\n",
    "AMENITY = 0\n",
    "LOCATION = 1\n",
    "# RESTUARANT_NAME = 3\n",
    "HOURS = 2\n",
    "# DISH = 5\n",
    "CUISINE = 3\n",
    "PRICE = 4\n",
    "ABSTAIN  = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Rating'] = RATING\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Amenity'] = AMENITY\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Location'] = LOCATION\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Restaurant_Name'] = RESTUARANT_NAME\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Hours'] = HOURS\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Dish'] = DISH\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Cuisine'] = CUISINE\n",
    "df_train_limited_chunks.Tag[df_train_limited_chunks.Tag=='Price'] = PRICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Labelling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labelling functions for Rating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_rating_star(x):\n",
    "    # Returns a label of rating if pattern of digit star's found in the phrase\n",
    "    n_grams = x.n_grams.lower()\n",
    "    if re.findall(\"[\\d]+[\\W]?star\", n_grams):\n",
    "        return RATING\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_rating_adj(x):\n",
    "    # Returns a label of rating if any adjective is within one edit distance or the base form of adjective is found in the phrase\n",
    "    adjectives = ['fresh', 'recommended', 'fair', 'recommendation', 'rated'\n",
    "       'terrific', 'well', 'awesome', 'awards', 'authentic', 'pleasing', 'favorite',\n",
    "        'lovely', 'really', 'decent', 'busy', 'superior','average'\n",
    "       'famous', 'poor', 'decent', 'simple', 'real', 'popular', 'wonderful',\n",
    "       'casual', 'perfect', 'massive', 'nearby', 'nice',\n",
    "       'delicious', 'winning', 'favourite',  'negative', 'award', 'positive', 'fancy',\n",
    "       'outstanding', 'good', 'amazing', 'recommend',\n",
    "       'strong', 'value','incredible',\n",
    "       'fantastic', 'classy', 'top', 'former', 'rated','reviews','horrible','terrible', \n",
    "       'local', 'excellent', 'place',\n",
    "       'tasty', 'rate', 'high', 'great']\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    for word in x.n_grams.lower().split():\n",
    "        for adjective in adjectives:\n",
    "            # ed.eval(adjective, word)<=1 or \\\n",
    "            if lemmatiser.lemmatize(word, pos = \"a\")==adjective:\n",
    "                return RATING\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_rating_adj_syn(x):\n",
    "    # Returns a label of rating if any word in the phrase is a synonym or an antonym within one edit distance of the mentioned words\n",
    "    adjectives = ['fresh', 'recommended', 'fair', 'recommendation', 'rated'\n",
    "       'terrific', 'well', 'awesome', 'awards', 'authentic', 'pleasing', 'favorite',\n",
    "        'lovely', 'really', 'decent', 'busy', 'superior',\n",
    "       'famous', 'poor', 'decent', 'simple', 'real', 'popular', 'wonderful',\n",
    "       'casual', 'perfect', 'massive', 'nearby', 'nice',\n",
    "       'delicious', 'winning', 'favourite',  'negative', 'award', 'positive', 'fancy',\n",
    "       'outstanding', 'good', 'amazing', 'recommend',\n",
    "       'strong', 'value','incredible',\n",
    "       'fantastic', 'classy', 'top', 'former', 'rated','reviews','horrible','terrible', \n",
    "       'local', 'excellent', 'place',\n",
    "       'tasty', 'rate', 'high', 'great']\n",
    "    synonyms = [] \n",
    "    antonyms = [] \n",
    "    for adj in adjectives:\n",
    "        for syn in wordnet.synsets(adj): \n",
    "            for l in syn.lemmas(): \n",
    "                synonyms.append(l.name()) \n",
    "#                 if l.antonyms(): \n",
    "#                     antonyms.append(l.antonyms()[0].name()) \n",
    "    \n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    for word in x.n_grams.lower().split():\n",
    "        for adjective in synonyms:\n",
    "            #ed.eval(adjective, word)<=1 or \\\n",
    "            if lemmatiser.lemmatize(word, pos = \"a\")==adjective:\n",
    "                return RATING\n",
    "#         for adjective in antonyms:\n",
    "#             #ed.eval(adjective, word)<=1 or \\\n",
    "#             if lemmatiser.lemmatize(word, pos = \"a\")==adjective:\n",
    "#                 return RATING\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labelling functions for Amenity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_amenity_lem(x):\n",
    "    # Returns a label of amenity if any word is within one edit distance of the mentioned adjectives or it's lemmatized form\n",
    "    amenities = ['formal', 'outdoor', 'friendly', 'parking', 'special'\n",
    "       'quiet', 'smoking', 'atmosphere', 'anniversary', 'birthday', 'tourist', 'reservation']\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    for word in x.n_grams.lower().split():\n",
    "        for adjective in amenities:\n",
    "            # ed.eval(adjective, word)<=1 or \n",
    "            if lemmatiser.lemmatize(word, pos = \"a\")==adjective:\n",
    "                return AMENITY\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_amenity_syn(x):\n",
    "    # Returns a label of amenity if any word in the phrase is a synonym or an antonym of the mentioned words within one edit distance\n",
    "    amenities = ['formal', 'outdoor', 'friendly', 'parking', 'special'\n",
    "       'quiet', 'smoking', 'atmosphere', 'anniversary', 'birthday', 'tourist', 'reservation']\n",
    "\n",
    "    synonyms = [] \n",
    "    antonyms = [] \n",
    "    for adj in amenities:\n",
    "        for syn in wordnet.synsets(adj): \n",
    "            for l in syn.lemmas(): \n",
    "                synonyms.append(l.name()) \n",
    "                if l.antonyms(): \n",
    "                    antonyms.append(l.antonyms()[0].name()) \n",
    "    \n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    for word in x.n_grams.lower().split():\n",
    "        for adjective in synonyms:\n",
    "            # ed.eval(adjective, word)<=1 or \n",
    "            if lemmatiser.lemmatize(word, pos = \"a\")==adjective:\n",
    "                return AMENITY\n",
    "#         for adjective in antonyms:\n",
    "#             #ed.eval(adjective, word)<=1 or \n",
    "#             if lemmatiser.lemmatize(word, pos = \"a\")==adjective:\n",
    "#                 return AMENITY\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labeling function for Location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_location_prep_before(x):\n",
    "    # Returns a label of location if the word before the phrase is a preposition mentioned\n",
    "    if (x.Pos_start>=1 and x.Query.split()[x.Pos_start - 1].lower() in ['in', 'near', 'above', 'over', 'by', 'along', 'around']) or \\\n",
    "    (x.Pos_start>1 and x.Query.split()[x.Pos_start - 2].lower() in  ['in', 'near', 'above', 'over', 'by', 'along', 'on']):\n",
    "        return LOCATION\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_location_prep_after(x):\n",
    "    # Returns a label of location if the word after the phrase is the word \"where\"\n",
    "    if x.Pos_end + 1 <= (len(x.Query.strip().split()) - 1) \\\n",
    "    and x.Query.split()[x.Pos_end + 1].lower() in ['where']:\n",
    "        return LOCATION\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labeling function for Hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_hours_keywords(x):\n",
    "    # Returns a label of hours if the the phrase contains any of the words mentioned below\n",
    "    keywords = ['hour', 'hours', 'am', 'a.m.', 'pm', 'p.m.', 'early', 'late']\n",
    "    for word in x.n_grams.lower().split():\n",
    "        if word in keywords:\n",
    "            return HOURS\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labeling function for Price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_price_keywords(x):\n",
    "    # Returns a label of price if the the phrase contains any of the words mentioned below\n",
    "    keywords = ['cheap', 'expensive', 'reasonable', 'bucks', 'dollars', 'price', 'prices', 'affordable', \\\n",
    "                'midpriced', 'high', 'least']\n",
    "    for word in x.n_grams.lower().split():\n",
    "        if word in keywords:\n",
    "            return PRICE\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labeling function for cuisine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def lf_cuisine_keywords(x):\n",
    "    # Returns a label of cuisine if the the phrase contains any of the words mentioned below\n",
    "    cuisine_words_list = ['Ainu', 'Albanian', 'Argentine', 'Andhra', 'Anglo-Indian', 'Arab', 'Armenian', 'Assyrian', 'Awadhi', \\\n",
    "                'Azerbaijani', 'Balochi', 'Belarusian', 'Bangladeshi', 'Bengali', 'Berber', 'Brazilian', 'Buddhist', \\\n",
    "                'Bulgarian', 'Cajun', 'Cantonese', 'Caribbean', 'Chechen', 'Chinese', 'Chinese Islamic', 'Circassian', \\\n",
    "                'Crimean Tatar', 'Cypriot', 'Danish', 'English', 'Estonian', 'French', 'Filipino', 'Georgian', 'German', \\\n",
    "                'Goan', 'Goan Catholic', 'Greek', 'Gujarati', 'Hyderabad', 'Hong Kong Western', 'Indian', 'Indian Chinese', \\\n",
    "                'Indian Singaporean', 'Indonesian', 'Inuit', 'Irish', 'Italian American', 'Italian', 'Jamaican', 'Japanese', \\\n",
    "                'Jewish', 'Karnataka', 'Kazakh', 'Keralite', 'Korean', 'Kurdish', 'Laotian', 'Lebanese', 'Latvian', \\\n",
    "                'Lithuanian', 'Louisiana Creole', 'Maharashtrian', 'Mangalorean', 'Malay', 'Malaysian Chinese', \\\n",
    "                'Malaysian Indian', 'Mediterranean', 'Mexican', 'Mordovian', 'Mughal', 'Native American', 'Nepalese', \\\n",
    "                'New Mexican', 'Odia', 'Parsi', 'Pashtun', 'Polish', 'Pennsylvania Dutch', 'Pakistani', 'Peranakan', \\\n",
    "                'Persian', 'Peruvian', 'Portuguese', 'Punjabi', 'Rajasthani', 'Romanian', 'Russian', 'Sami', 'Serbian', \\\n",
    "                'Sindhi', 'Slovak', 'Slovenian', 'Somali', 'South Indian', 'Soviet', 'Spanish', 'Sri Lankan', 'Taiwanese', \\\n",
    "                'Tatar', 'Thai', 'Turkish', 'Tamil', 'Udupi', 'Ukrainian', 'Vietnamese', 'Yamal', 'Zambian', 'Zanzibari', \\\n",
    "               'cuisine', 'cuisines']\n",
    "    new_cuisine_list = []\n",
    "    for word in cuisine_words_list:\n",
    "        new_cuisine_list.append(word.lower())\n",
    "    for word in x.n_grams.lower().split():\n",
    "        if word in new_cuisine_list:\n",
    "            return CUISINE\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_amenity_train = df_train_limited_chunks[df_train_limited_chunks['Tag'].isin([0,1, 2, 3, 4, -1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_lf_rating_amenity, df_test_lf_rating_amenity, y_lf_train, y_lf_test = train_test_split(df_rating_amenity_train.drop('Tag', axis = 1),\\\n",
    "                                                                                df_rating_amenity_train['Tag'], test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [lf_amenity_lem, lf_amenity_syn, \\\n",
    "       lf_location_prep_before, lf_location_prep_after, lf_hours_keywords, lf_price_keywords, lf_cuisine_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_grams</th>\n",
       "      <th>Query</th>\n",
       "      <th>Pos_start</th>\n",
       "      <th>Pos_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7315</th>\n",
       "      <td>taco bueno phone number</td>\n",
       "      <td>what is taco bueno phone number</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>a chinese restaurant</td>\n",
       "      <td>id like to find a chinese restaurant nearby th...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8242</th>\n",
       "      <td>the service</td>\n",
       "      <td>where can i find a good sauce the service does...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7604</th>\n",
       "      <td>this area</td>\n",
       "      <td>what place has the best reviews for dining in ...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>breakfast restaurants</td>\n",
       "      <td>i want a list of breakfast restaurants that se...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      n_grams  \\\n",
       "7315  taco bueno phone number   \n",
       "4587     a chinese restaurant   \n",
       "8242              the service   \n",
       "7604                this area   \n",
       "4067    breakfast restaurants   \n",
       "\n",
       "                                                  Query  Pos_start  Pos_end  \n",
       "7315                    what is taco bueno phone number          2        5  \n",
       "4587  id like to find a chinese restaurant nearby th...          5        7  \n",
       "8242  where can i find a good sauce the service does...          7        8  \n",
       "7604  what place has the best reviews for dining in ...          9       10  \n",
       "4067  i want a list of breakfast restaurants that se...          5        6  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_lf_rating_amenity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6076/6076 [00:11<00:00, 532.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2604/2604 [00:04<00:00, 537.11it/s]\n"
     ]
    }
   ],
   "source": [
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train_lf_rating_amenity)\n",
    "L_dev = applier.apply(df=df_test_lf_rating_amenity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at the coverage of different labeling functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelling function stars coverage: 0.7%\n",
      "Labelling function lemmas of amenity coverage: 4.8%\n",
      "Labelling function synonyms of amenity coverage: 5.2%\n",
      "Labelling function synonyms of location_before_prep coverage: 12.9%\n",
      "Labelling function synonyms of location_after_prep coverage: 0.6%\n",
      "Labelling function synonyms of hours coverage: 2.2%\n",
      "Labelling function synonyms of price coverage: 3.6%\n",
      "Labelling function synonyms of cuisine coverage: 9.1%\n"
     ]
    }
   ],
   "source": [
    "coverage_amenity_lem, coverage_amenity_syn, coverage_loc_before, \\\n",
    "coverage_loc_after, coverage_hours, coverage_price, coverage_cuisine = (L_train != ABSTAIN).mean(axis=0)\n",
    "print(f\"Labelling function stars coverage: {coverage_stars * 100:.1f}%\")\n",
    "# print(f\"Labelling function adjectives coverage: {coverage_adjectives * 100:.1f}%\")\n",
    "# print(f\"Labelling function synonyms of adjectives coverage: {coverage_synonyms * 100:.1f}%\")\n",
    "print(f\"Labelling function lemmas of amenity coverage: {coverage_amenity_lem * 100:.1f}%\")\n",
    "print(f\"Labelling function synonyms of amenity coverage: {coverage_amenity_syn * 100:.1f}%\")\n",
    "print(f\"Labelling function synonyms of location_before_prep coverage: {coverage_loc_before * 100:.1f}%\")\n",
    "print(f\"Labelling function synonyms of location_after_prep coverage: {coverage_loc_after * 100:.1f}%\")\n",
    "print(f\"Labelling function synonyms of hours coverage: {coverage_hours * 100:.1f}%\")\n",
    "print(f\"Labelling function synonyms of price coverage: {coverage_price * 100:.1f}%\")\n",
    "print(f\"Labelling function synonyms of cuisine coverage: {coverage_cuisine * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_amenity_lem</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_amenity_syn</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.052172</td>\n",
       "      <td>0.050362</td>\n",
       "      <td>0.002633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_location_prep_before</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.129197</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.002962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_location_prep_after</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.001317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_hours_keywords</th>\n",
       "      <td>4</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.021725</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_price_keywords</th>\n",
       "      <td>5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.036208</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_cuisine_keywords</th>\n",
       "      <td>6</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.091343</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.001646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j Polarity  Coverage  Overlaps  Conflicts\n",
       "lf_amenity_lem           0      [0]  0.048387  0.048387   0.000658\n",
       "lf_amenity_syn           1      [0]  0.052172  0.050362   0.002633\n",
       "lf_location_prep_before  2      [1]  0.129197  0.003456   0.002962\n",
       "lf_location_prep_after   3      [1]  0.006419  0.001810   0.001317\n",
       "lf_hours_keywords        4      [2]  0.021725  0.000494   0.000494\n",
       "lf_price_keywords        5      [4]  0.036208  0.000823   0.000823\n",
       "lf_cuisine_keywords      6      [3]  0.091343  0.001646   0.001646"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_int = y_lf_test.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at the performance of different labelling functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lf_amenity_lem</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.041475</td>\n",
       "      <td>0.041475</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_amenity_syn</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.047235</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>115</td>\n",
       "      <td>8</td>\n",
       "      <td>0.934959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_location_prep_before</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.132488</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>0.004224</td>\n",
       "      <td>315</td>\n",
       "      <td>30</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_location_prep_after</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_hours_keywords</th>\n",
       "      <td>4</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_price_keywords</th>\n",
       "      <td>5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.031874</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>65</td>\n",
       "      <td>18</td>\n",
       "      <td>0.783133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_cuisine_keywords</th>\n",
       "      <td>6</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>236</td>\n",
       "      <td>16</td>\n",
       "      <td>0.936508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "lf_amenity_lem           0      [0]  0.041475  0.041475   0.001536      107   \n",
       "lf_amenity_syn           1      [0]  0.047235  0.043011   0.003072      115   \n",
       "lf_location_prep_before  2      [1]  0.132488  0.005760   0.004224      315   \n",
       "lf_location_prep_after   3      [1]  0.006528  0.003456   0.001920        5   \n",
       "lf_hours_keywords        4      [2]  0.020737  0.000768   0.000768       46   \n",
       "lf_price_keywords        5      [4]  0.031874  0.002304   0.002304       65   \n",
       "lf_cuisine_keywords      6      [3]  0.096774  0.003840   0.003840      236   \n",
       "\n",
       "                         Incorrect  Emp. Acc.  \n",
       "lf_amenity_lem                   1   0.990741  \n",
       "lf_amenity_syn                   8   0.934959  \n",
       "lf_location_prep_before         30   0.913043  \n",
       "lf_location_prep_after          12   0.294118  \n",
       "lf_hours_keywords                8   0.851852  \n",
       "lf_price_keywords               18   0.783133  \n",
       "lf_cuisine_keywords             16   0.936508  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_dev, lfs=lfs)\\\n",
    ".lf_summary(y_test_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking the total coverage of all the labelling functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.326036866359447"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total coverage\n",
    "((L_dev != -1).sum(1) > 0).sum() / len(L_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking the accuracy of the Majority Label voter model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   42.7%\n"
     ]
    }
   ],
   "source": [
    "majority_model = MajorityLabelVoter(cardinality=5)\n",
    "preds_train = majority_model.predict(L=L_train)\n",
    "\n",
    "majority_acc = majority_model.score(L=L_dev, Y=y_test_int)[\"accuracy\"]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking the accuracy of the Label Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Model Accuracy:     42.7%\n"
     ]
    }
   ],
   "source": [
    "label_model = LabelModel(cardinality=5, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=3000, lr=1e-5)#, class_balance=[0.3, 0.3, 0.2, 0.2])\n",
    "\n",
    "label_model_acc = label_model.score(L=L_dev, Y=y_test_int)[\"accuracy\"]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at the confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[223,  76,  20, 140,   0],\n",
       "       [137, 386,  18, 177,   7],\n",
       "       [119,  75,  61, 133,   3],\n",
       "       [112,  88,  12, 376,   7],\n",
       "       [121,  72,  14, 160,  67]], dtype=int64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(label_model.predict(L=L_dev), y_test_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_grams</th>\n",
       "      <th>Query</th>\n",
       "      <th>Pos_start</th>\n",
       "      <th>Pos_end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>french cuisine</td>\n",
       "      <td>can you find a restaurant near downtown that s...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>credit cards</td>\n",
       "      <td>does aiea manapua and snacks accept credit cards</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>food</td>\n",
       "      <td>find me a good sports bar that serves food</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>glen cove ny</td>\n",
       "      <td>does china palace in glen cove ny have a lunch...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>any tourist type sightseeing restaurants</td>\n",
       "      <td>are there any tourist type sightseeing restaur...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       n_grams  \\\n",
       "958                             french cuisine   \n",
       "1726                              credit cards   \n",
       "2567                                      food   \n",
       "1795                              glen cove ny   \n",
       "628   any tourist type sightseeing restaurants   \n",
       "\n",
       "                                                  Query  Pos_start  Pos_end  \\\n",
       "958   can you find a restaurant near downtown that s...          9       10   \n",
       "1726   does aiea manapua and snacks accept credit cards          6        7   \n",
       "2567         find me a good sports bar that serves food          8        8   \n",
       "1795  does china palace in glen cove ny have a lunch...          4        6   \n",
       "628   are there any tourist type sightseeing restaur...          2        6   \n",
       "\n",
       "      label  \n",
       "958       3  \n",
       "1726      0  \n",
       "2567      0  \n",
       "1795      1  \n",
       "628       0  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = label_model.predict_proba(L_train).argmax(axis=1)\n",
    "df_train_lf_rating_amenity['label'] = train_labels\n",
    "df_train_lf_rating_amenity.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
