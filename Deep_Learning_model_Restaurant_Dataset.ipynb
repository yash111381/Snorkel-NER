{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning model - Restaurant Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvraAQEm8the",
        "colab_type": "text"
      },
      "source": [
        "# Restaurant Dataset - Deep Learning Model (BiLSTM) with Elmo pre-trained embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y96Xmew6845Q",
        "colab_type": "text"
      },
      "source": [
        "Importing necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBwfOtK3b-t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Input\n",
        "from keras.layers.merge import add\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQkm1GGb2M_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOVqjZiW89JC",
        "colab_type": "text"
      },
      "source": [
        "Here, I initialize the tensorflow session and import Elmo pre-trainied embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4R_pLJ4cKjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgsCcFPB9DJg",
        "colab_type": "text"
      },
      "source": [
        "**Preprocessing the data file to make the required dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEV1CFxzcUr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ret_df_file(file):\n",
        "    with open(file, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "        size = len(lines) \n",
        "        idx_list = [idx + 1 for idx, val in\n",
        "                enumerate(lines) if val == '\\n'] \n",
        "        res = [lines[i: j-1] for i, j in\n",
        "            zip([0] + idx_list, idx_list + \n",
        "            ([size] if idx_list[-1] != size else []))] \n",
        "        queries = ['' for i in range(len(res))]\n",
        "        tags = []\n",
        "        unigrams = []\n",
        "        for i, ele in enumerate(res):\n",
        "            for j, actual_str in enumerate(ele):\n",
        "                res[i][j] = actual_str.split('\\t')\n",
        "                res[i][j][-1] = res[i][j][-1].replace('\\n', '')\n",
        "                tags.append(res[i][j][0])\n",
        "                if j!=0:\n",
        "                    queries[i] = queries[i] + ' ' + res[i][j][-1]\n",
        "                else:\n",
        "                    queries[i] = res[i][j][-1]\n",
        "                unigrams.append(res[i][j][-1])\n",
        "    df_queries = []\n",
        "    pos = []\n",
        "    for i, ele in enumerate(res):\n",
        "        for j, actual_str in enumerate(ele):\n",
        "            df_queries.append(\"Sentence: \"+str(i))\n",
        "            pos.append(j)\n",
        "    return pd.DataFrame({\"Word\": unigrams, \"Tag\": tags, \"Query\": df_queries})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6emLxb7du6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = ret_df_file(\"restauranttrain.bio\")\n",
        "df_test = ret_df_file(\"restauranttest.bio\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAd-i141d5gL",
        "colab_type": "code",
        "outputId": "bc9dde84-8283-4a25-b78c-a0db4f6d2aa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Query</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>B-Rating</td>\n",
              "      <td>Sentence: 0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>start</td>\n",
              "      <td>I-Rating</td>\n",
              "      <td>Sentence: 0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>restaurants</td>\n",
              "      <td>O</td>\n",
              "      <td>Sentence: 0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>with</td>\n",
              "      <td>O</td>\n",
              "      <td>Sentence: 0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>inside</td>\n",
              "      <td>B-Amenity</td>\n",
              "      <td>Sentence: 0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Word        Tag        Query\n",
              "0            2   B-Rating  Sentence: 0\n",
              "1        start   I-Rating  Sentence: 0\n",
              "2  restaurants          O  Sentence: 0\n",
              "3         with          O  Sentence: 0\n",
              "4       inside  B-Amenity  Sentence: 0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qV2C4Kdd6lZ",
        "colab_type": "code",
        "outputId": "623661ff-17a4-4cc8-d4df-e412fd7aa97e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "words = set(list(df_train['Word'].values))\n",
        "words.add('PADword')\n",
        "n_words = len(words)\n",
        "n_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3805"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3bBtTVOf-B4",
        "colab_type": "code",
        "outputId": "d4e213c0-7331-4ebc-c7cc-d6af2e4cc37e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tags = list(set(df_train[\"Tag\"].values))\n",
        "n_tags = len(tags)\n",
        "n_tags"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7S38rvi9I19",
        "colab_type": "text"
      },
      "source": [
        "**Function for getting each query and making a batch for training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBwR8W7hgC6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Query\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STdusIb6go44",
        "colab_type": "code",
        "outputId": "378b7055-9a2f-45c9-9d5f-3e1cbb7d4439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "getter = SentenceGetter(df_train)\n",
        "sent = getter.get_next()\n",
        "print(sent)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('34', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSt8-aU-gq_E",
        "colab_type": "code",
        "outputId": "82eebe09-8d10-4b8b-ca93-7c92aeef0d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences = getter.sentences\n",
        "print(len(sentences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyZwA8zfgw5G",
        "colab_type": "code",
        "outputId": "c26081ba-3c40-4982-d450-6ccac48a8e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "largest_sen = max(len(sen) for sen in sentences)\n",
        "print('biggest sentence has {} words'.format(largest_sen))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "biggest sentence has 35 words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIYIqAIA9Sm6",
        "colab_type": "text"
      },
      "source": [
        "**Looking at the frequency of the number of words in the queries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrUZjn1GhQKC",
        "colab_type": "code",
        "outputId": "1e8733d9-441b-4cb6-d1ba-c43324644d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "\n",
        "plt.hist([len(sen) for sen in sentences], bins= 50)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYuhLUkX+D4U2sGFjoRZqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDzu98a7hSeX",
        "colab_type": "code",
        "outputId": "e9f36601-3769-46d9-9870-202ba32ea18b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "words2index = {w:i for i,w in enumerate(words)}\n",
        "tags2index = {t:i for i,t in enumerate(tags)}\n",
        "print(words2index['my'])\n",
        "print(tags2index['B-Location'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2228\n",
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DH1wkFGhVha",
        "colab_type": "code",
        "outputId": "26f99002-e483-4b36-de22-604df1be863a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "max_len = 15\n",
        "X = [[w[0]for w in s] for s in sentences]\n",
        "new_X = []\n",
        "for seq in X:\n",
        "    new_seq = []\n",
        "    for i in range(max_len):\n",
        "        try:\n",
        "            new_seq.append(seq[i])\n",
        "        except:\n",
        "            new_seq.append(\"PADword\")\n",
        "    new_X.append(new_seq)\n",
        "new_X[15]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['could',\n",
              " 'you',\n",
              " 'find',\n",
              " 'me',\n",
              " 'a',\n",
              " 'high',\n",
              " 'end',\n",
              " 'halal',\n",
              " 'restaurant',\n",
              " 'open',\n",
              " 'until',\n",
              " '12',\n",
              " 'pm',\n",
              " 'PADword',\n",
              " 'PADword']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhEAvNLU9cgR",
        "colab_type": "text"
      },
      "source": [
        "**Padding all the sequences to a length of 15** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTXYVgXkhgLo",
        "colab_type": "code",
        "outputId": "8f2026e5-1b3e-4449-f939-4e172bf551c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y = [[tags2index[w[1]] for w in s] for s in sentences]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tags2index[\"O\"])\n",
        "y[15]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  3,  3,  3,  3,  3,  3,  1,  3, 16,  0,  0,  0,  3,  3],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lShcZVwo9ioU",
        "colab_type": "text"
      },
      "source": [
        "**Spliting the data in train and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBKe847WhqSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tr, X_te, y_tr, y_te = train_test_split(new_X, y, test_size=0.1, random_state=2018)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ0lHrOB9ptH",
        "colab_type": "text"
      },
      "source": [
        "**Defining the structure of the Elmo embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aufo_mnhz7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ElmoEmbedding(x):\n",
        "    return elmo_model(inputs={\n",
        "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
        "                            \"sequence_len\": tf.constant(batch_size*[max_len])\n",
        "                      },\n",
        "                      signature=\"tokens\",\n",
        "                      as_dict=True)[\"elmo\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljsdoawf96d-",
        "colab_type": "text"
      },
      "source": [
        "**Defining the model architecture with BiLSTMs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l85M9zfbh4hz",
        "colab_type": "code",
        "outputId": "1660e245-cda8-440f-966a-f4a587db46ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input_text = Input(shape=(max_len,), dtype=tf.string)\n",
        "embedding = Lambda(ElmoEmbedding, output_shape=(max_len, 1024))(input_text)\n",
        "x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
        "x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                           recurrent_dropout=0.2, dropout=0.2))(x)\n",
        "x = add([x, x_rnn])  # residual connection to the first biLSTM\n",
        "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiY-Gv5Ih76Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(input_text, out)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTYD8SpEh-zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tr, X_val = X_tr[:190*batch_size], X_tr[-25*batch_size:]\n",
        "y_tr, y_val = y_tr[:190*batch_size], y_tr[-25*batch_size:]\n",
        "y_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)\n",
        "y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ALu7Y1P-CpG",
        "colab_type": "text"
      },
      "source": [
        "**Training the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shlqmhiciA0l",
        "colab_type": "code",
        "outputId": "96b6d03c-fa70-4974-9774-6f4185445ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "history = model.fit(np.array(X_tr), y_tr, validation_data=(np.array(X_val), y_val),\n",
        "                    batch_size=batch_size, epochs=3, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6080 samples, validate on 800 samples\n",
            "Epoch 1/3\n",
            "6080/6080 [==============================] - 970s 160ms/step - loss: 0.4223 - acc: 0.8827 - val_loss: 0.2803 - val_acc: 0.9147\n",
            "Epoch 2/3\n",
            "6080/6080 [==============================] - 955s 157ms/step - loss: 0.2461 - acc: 0.9261 - val_loss: 0.2646 - val_acc: 0.9213\n",
            "Epoch 3/3\n",
            "6080/6080 [==============================] - 953s 157ms/step - loss: 0.1992 - acc: 0.9379 - val_loss: 0.2620 - val_acc: 0.9227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvQ4vwv6-Jxi",
        "colab_type": "text"
      },
      "source": [
        "**Checking the performance of the model on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KeRXdDAiCvv",
        "colab_type": "code",
        "outputId": "2f95bc0c-84da-479f-8036-7bb1a04a2bcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "X_te = X_te[:23*batch_size]\n",
        "test_pred = model.predict(np.array(X_te), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "736/736 [==============================] - 73s 99ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwQINrJoib_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "idx2tag = {i: w for w, i in tags2index.items()}\n",
        "\n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[p_i].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "\n",
        "def test2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            out_i.append(idx2tag[p].replace(\"PADword\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "    \n",
        "pred_labels = pred2label(test_pred)\n",
        "test_labels = test2label(y_te[:23*32])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyy_SEtP-WCX",
        "colab_type": "text"
      },
      "source": [
        "**Looking at the classification report for the model predictions on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBol2gK2icOn",
        "colab_type": "code",
        "outputId": "c1a0efa2-be20-452e-c079-713ce71891d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "\n",
        "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n",
        "print(classification_report(test_labels, pred_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score: 69.2%\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        Cuisine       0.82      0.78      0.80       304\n",
            "       Location       0.73      0.74      0.74       376\n",
            "        Amenity       0.57      0.41      0.47       256\n",
            "           Dish       0.60      0.66      0.63       133\n",
            "         Rating       0.67      0.73      0.70       101\n",
            "          Hours       0.61      0.57      0.59        90\n",
            "Restaurant_Name       0.77      0.77      0.77       177\n",
            "          Price       0.80      0.70      0.75        64\n",
            "\n",
            "      micro avg       0.71      0.68      0.69      1501\n",
            "      macro avg       0.71      0.68      0.69      1501\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ctHBipRihzO",
        "colab_type": "code",
        "outputId": "b7be65c3-b930-4457-ad68-c15b70d23140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Micro-precision is \",(0.82+0.73+0.57+0.67+0.61+0.8)/6)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Micro-precision is  0.6999999999999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT2zxcUcl8dP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}